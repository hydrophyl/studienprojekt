{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff6beee-ff59-4832-9c20-18c9ef48481c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from datetime import timedelta\n",
    "import os\n",
    "import wget\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "\n",
    "today = datetime.date.today()\n",
    "yesterday = today - timedelta(days = 1)\n",
    "\n",
    "daysinmonth = int(str(today)[-2:])\n",
    "if daysinmonth < 7:\n",
    "    daysinweek = daysinmonth\n",
    "else:\n",
    "    daysinweek = 7\n",
    "    \n",
    "print(daysinmonth)\n",
    "print(daysinweek)\n",
    "\n",
    "#create list that contains 7 days since today\n",
    "week = []\n",
    "for i in range(daysinweek):\n",
    "    week.append(today - timedelta(days = i))\n",
    "    week[i] = str(week[i])\n",
    "\n",
    "print(week)\n",
    "\n",
    "#create list that contains 30 days since today\n",
    "month = []\n",
    "for i in range(daysinmonth):\n",
    "    month.append(today - timedelta(days = i))\n",
    "    month[i] = str(month[i])\n",
    "\n",
    "print(month)\n",
    "\n",
    "#convert to string for managing files\n",
    "yesterday = str(yesterday)\n",
    "today = str(today)\n",
    "\n",
    "#define sensor_id here\n",
    "sensor_id = \"12776407\"\n",
    "link = 'https://api-rrd.madavi.de/data_csv/csv-files/'+ today + '/data-esp8266-'+sensor_id+'-'+ today + '.csv'\n",
    "\n",
    "#check if todays data already downloaded\n",
    "def check():  \n",
    "    filename = 'data-esp8266-'+sensor_id+'-'+today+'.csv'\n",
    "    files = os.listdir()\n",
    "    for file in files:\n",
    "        if str(file) == str(filename):\n",
    "            os.remove(filename) # if exist, remove it \n",
    "    return\n",
    "\n",
    "\n",
    "# check if todays data is available or not, if not then download latest data of yesterday\n",
    "req = urllib.request.Request(link)\n",
    "try: \n",
    "    urllib.request.urlopen(req)\n",
    "    check()\n",
    "    filename = 'data-esp8266-'+sensor_id+'-'+today+'.csv'\n",
    "    print(\"Todays data will be downloaded!\")\n",
    "    wget.download(link)\n",
    "except urllib.error.URLError as e:\n",
    "    print(e.reason)\n",
    "    print(\"Todays data isn't updated on server\")\n",
    "    print(\"Downloading yesterdays data\")\n",
    "    today = yesterday\n",
    "    filename = 'data-esp8266-'+sensor_id+'-'+today+'.csv'\n",
    "    check()\n",
    "    link = 'https://api-rrd.madavi.de/data_csv/csv-files/'+ today + '/data-esp8266-12776407-'+ today + '.csv'\n",
    "    wget.download(link)\n",
    "\n",
    "#read dataframe of today\n",
    "df = pd.read_csv(filename,sep=';')\n",
    "\n",
    "#convert Time string to datetime type\n",
    "format = \"%Y/%m/%d %H:%M:%S\"\n",
    "def convert_datetime(dt_string):\n",
    "    dt_object = datetime.datetime.strptime(dt_string, format)\n",
    "    return dt_object\n",
    "\n",
    "df['Time'] = df['Time'].apply(convert_datetime)\n",
    "\n",
    "#plotting latest data of one day in plotly\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "def plotting(df):\n",
    "    # Create figure with secondary y-axis\n",
    "    fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "    # Add traces\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=df['Time'], y=df['SDS_P1'], name=\"PM2.5\", line=dict(color='#7355A3')),\n",
    "        secondary_y=False,\n",
    "\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=df['Time'], y=df['SDS_P2'], name=\"PM10\", line=dict(color='#E47988')),\n",
    "        secondary_y=True,\n",
    "    )\n",
    "\n",
    "    # Add figure title\n",
    "    fig.update_layout(\n",
    "        title_text=\"PM2.5 & PM10\",\n",
    "        height=600\n",
    "    )\n",
    "\n",
    "    # Set x-axis title\n",
    "    fig.update_xaxes(title_text=\"Time\")\n",
    "\n",
    "    # Set y-axes titles\n",
    "    fig.update_yaxes(title_text=\"PM2.5\", secondary_y=False)\n",
    "    fig.update_yaxes(title_text=\"PM10\", secondary_y=True)\n",
    "\n",
    "    fig.show()\n",
    "    \n",
    "plotting(df)\n",
    "\n",
    "#WEEKLY and MONTHLY datas fetching\n",
    "#Check if folder is already exists -> if yes then delete it\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "def checkfolder(folder):\n",
    "    path = './' + folder\n",
    "    isdir = os.path.isdir(path)\n",
    "    if isdir == True:\n",
    "        shutil.rmtree(path)\n",
    "        print(\"% s removed successfully\" % path)\n",
    "    else:\n",
    "        print(\"Creating \" + folder)\n",
    "\n",
    "#download weekly datas\n",
    "def download_datas(folder,timeinterval):\n",
    "    path = './' + folder + ''\n",
    "    os.mkdir(folder)\n",
    "    for date in timeinterval:\n",
    "        date=str(date)\n",
    "        link = 'https://api-rrd.madavi.de/data_csv/csv-files/'+ date + '/data-esp8266-12776407-'+ date + '.csv'\n",
    "        wget.download(link, path)\n",
    "        \n",
    "def join_csvfiles(folder):\n",
    "    path = './' + folder + ''\n",
    "    all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "    df_from_each_file = (pd.read_csv(f, sep=';') for f in all_files)\n",
    "    df_merged   = pd.concat(df_from_each_file, ignore_index=True)\n",
    "    df_merged.to_csv(\"./\"+folder+\"/merged.csv\")\n",
    "\n",
    "checkfolder(\"week\")      \n",
    "download_datas(\"week\",week)    \n",
    "join_csvfiles(\"week\")\n",
    "\n",
    "df_week = pd.read_csv(\"./week/merged.csv\",sep=\",\")\n",
    "\n",
    "#plotting latest data of one week in plotly\n",
    "df_week['Time'] = df_week['Time'].apply(convert_datetime)\n",
    "plotting(df_week)\n",
    "\n",
    "#fetch and plot data of one month\n",
    "checkfolder(\"month\")\n",
    "download_datas(\"month\", month)\n",
    "join_csvfiles(\"month\")\n",
    "df_month = pd.read_csv(\"./month/merged.csv\",sep=\",\")\n",
    "df_month['Time'] = df_month['Time'].apply(convert_datetime)\n",
    "plotting(df_month)\n",
    "\n",
    "#find last month and export to string\n",
    "last_month = int(str(today)[5:7]) #10\n",
    "last_month = 12 if last_month == 1 else last_month-1\n",
    "if len(str(last_month)) == 1:\n",
    "    last_month = \"0\" + str(last_month) #09\n",
    "\n",
    "#download data of last month\n",
    "last_month_link = \"https://api-rrd.madavi.de/data_csv/2021/\"+last_month+\"/data-esp8266-\"+sensor_id+\"-2021-\"+last_month+\".zip\"\n",
    "checkfolder(last_month)\n",
    "path = './'+last_month\n",
    "os.mkdir(last_month)\n",
    "wget.download(last_month_link, path)\n",
    "\n",
    "from zipfile import ZipFile \n",
    "dir = os.listdir(path)\n",
    "file = dir[0]\n",
    "path = path+\"/\"+file\n",
    "# open the zip file in read mode\n",
    "with ZipFile(path, 'r') as zip: \n",
    "    # extract all files to directory\n",
    "    zip.extractall(last_month)\n",
    "    \n",
    "os.remove(path) #delete zip file\n",
    "\n",
    "join_csvfiles(last_month)\n",
    "\n",
    "df_last_month = pd.read_csv(\"./\"+last_month+\"/merged.csv\",sep=\",\",low_memory=False)\n",
    "df_last_month.head()\n",
    "\n",
    "df_last_month['Time'] = pd.to_datetime(df_last_month['Time'], errors='coerce')\n",
    "plotting(df_last_month)\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import requests_html \n",
    "\n",
    "months = []\n",
    "with requests_html.HTMLSession() as s:\n",
    "    try:\n",
    "        r = s.get('https://api-rrd.madavi.de/csvfiles.php?sensor=esp8266-12776407')\n",
    "        links = r.html.links\n",
    "        for link in links:\n",
    "            if link[-3:] == \"zip\":\n",
    "                months.append(link)\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "print(months)\n",
    "\n",
    "checkfolder(\"all\")\n",
    "path = './all'\n",
    "os.mkdir(\"all\")\n",
    "\n",
    "for link in months:\n",
    "    download_link = \"https://api-rrd.madavi.de/\"+link\n",
    "    wget.download(download_link, path)\n",
    "    \n",
    "\n",
    "days = os.listdir(\"./all\")\n",
    "for day in days:\n",
    "    path=\"./all/\"+day\n",
    "    with ZipFile(path, 'r') as zip: \n",
    "        # extract all files to directory\n",
    "        zip.extractall(\"all\")\n",
    "    os.remove(path)\n",
    "\n",
    "for date in month:\n",
    "    path = './all'\n",
    "    date=str(date)\n",
    "    link = 'https://api-rrd.madavi.de/data_csv/csv-files/'+ date + '/data-esp8266-'+sensor_id+'-'+ date + '.csv'\n",
    "    wget.download(link, path)\n",
    "\n",
    "join_csvfiles(\"all\")\n",
    "df_all = pd.read_csv(\"./all/merged.csv\",sep=\",\")\n",
    "df_all['Time'] = df_all['Time'].apply(convert_datetime)\n",
    "plotting(df_all)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
